{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 505 Homework 05: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESOURCES: I used the resources posted along with the pytorch documentation and chat-gpt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy.random import shuffle, seed, choice, randint,rand,normal,permutation\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split,Dataset,DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One: Character-Level Generative Model (20 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 10879 characters long.\n",
      "There are 73 characters in the text.\n",
      "Character set: ['\\n', ' ', '!', '\"', '&', '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '6', '9', ':', ';', '<', '=', '>', 'A', 'B', 'C', 'D', 'E', 'F', 'H', 'I', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}'].\n",
      "Input sequence:\n",
      "\n",
      "\n",
      "/* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpos\n",
      "Target sequence:\n",
      "\n",
      "/* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose\n",
      "\n",
      "Input sequence:\n",
      "\n",
      "/* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose\n",
      "Target sequence:\n",
      "/* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose:\n",
      "\n",
      "Input sequence:\n",
      "/* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose:\n",
      "Target sequence:\n",
      "* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose: \n",
      "\n",
      "Input sequence:\n",
      "* File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose: \n",
      "Target sequence:\n",
      " File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose: T\n",
      "\n",
      "Input sequence:\n",
      " File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose: T\n",
      "Target sequence:\n",
      "File: BSTExperiment.java\n",
      " * Authors: Brian Borucki and Wayne Snyder\n",
      " * Date: 9/10/13\n",
      " * Purpose: Th\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TEXT INPUT & PROCESSING ##\n",
    "\n",
    "with open(\"data/BSTExperiment.java.txt\", \"r\") as text_file:\n",
    "    text = text_file.read()\n",
    "text[:100]\n",
    "print(f\"Text is {len(text)} characters long.\")\n",
    "size = 10000\n",
    "text = text[:size]\n",
    "chars_in_text = sorted(list(set(text)))\n",
    "num_chars = len(chars_in_text)\n",
    "print(f'There are {num_chars} characters in the text.')\n",
    "print(f'Character set: {chars_in_text}.')\n",
    "\n",
    "def char2int(c):\n",
    "    return chars_in_text.index(c)\n",
    "\n",
    "def int2char(i):\n",
    "    return chars_in_text[i]\n",
    "sample_len = 100\n",
    "\n",
    "# Creating lists that will hold our input and target sample sequences\n",
    "\n",
    "input_seq_chars = []\n",
    "target_seq_chars = []\n",
    "\n",
    "for k in range(len(text)-sample_len+1):\n",
    "\n",
    "    # Remove last character for input sequence\n",
    "    input_seq_chars.append(text[k:k+sample_len-1])\n",
    "\n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq_chars.append(text[k+1:k+sample_len])\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Input sequence:\\n{input_seq_chars[i]}')\n",
    "    print(f'Target sequence:\\n{target_seq_chars[i]}')\n",
    "    print()\n",
    "\n",
    "input_seq = []\n",
    "target_seq = []\n",
    "\n",
    "for i in range(len(input_seq_chars)):\n",
    "    input_seq.append( [char2int(ch) for ch in input_seq_chars[i]])\n",
    "    target_seq.append([char2int(ch) for ch in target_seq_chars[i]])\n",
    "\n",
    "print(input_seq[0])\n",
    "\n",
    "# convert an integer into a one-hot encoding of the given size (= number of characters)\n",
    "def int2OneHot(X,size):\n",
    "\n",
    "    def int2OneHot1(x,size=10):\n",
    "        tmp = np.zeros(size)\n",
    "        tmp[int(x)] = 1.0\n",
    "        return tmp\n",
    "\n",
    "    return np.array([ int2OneHot1(x, size) for x in X ]).astype('double')\n",
    "\n",
    "int2OneHot( np.array([ 2,3,1,2,3,4 ]),10)\n",
    "\n",
    "# do the same thing, but for a list/array of integers\n",
    "\n",
    "def seq2OneHot(seq,size):\n",
    "    return np.array([ int2OneHot(x, size) for x in seq ])\n",
    "\n",
    "seq2OneHot( np.array([[ 2,3,1,2,3,4 ],[ 2,3,1,2,3,4 ],[ 2,3,1,2,3,4 ]]),10)\n",
    "\n",
    "# Convert our input sequences to one-hot form\n",
    "\n",
    "input_seq = seq2OneHot(input_seq,size=num_chars)\n",
    "print(\"INPUT SEQ Shape:\",input_seq.shape)\n",
    "\n",
    "# Convert our target sequences to one-hot form\n",
    "\n",
    "target_seq = seq2OneHot(target_seq,size=num_chars)\n",
    "print(\"TARGET SEQ Shape\", target_seq.shape)\n",
    "\n",
    "# Convert to tensors\n",
    "\n",
    "input_seq = torch.Tensor(input_seq).type(torch.DoubleTensor)\n",
    "target_seq = torch.Tensor(target_seq).type(torch.DoubleTensor)\n",
    "\n",
    "print(\"TEXT READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two:  Word-Level Generative Model (40 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three:  Part-of-Speech Tagging (40 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
